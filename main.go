package main

import (
	"bufio"
	"context"
	"fmt"
	"os"
	"strings"

	"github.com/smallnest/langgraphgo/graph"
	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/openai"
)

type MyState struct {
	Count   int
	Message string
}

// ChatState å®šä¹‰å¯¹è¯çŠ¶æ€ç±»åž‹
type ChatState struct {
	Messages []llms.MessageContent
}

func main() {
	demo1()
}

func demo() {
	// g := graph.NewStateGraph[MyState]()
}

// original version
func demo1() {
	fmt.Println("=== Ollama DeepSeek 14B å¯¹è¯ Demo ===")
	fmt.Println("æç¤ºï¼šè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
	fmt.Println()

	// é…ç½® Ollamaï¼ˆOpenAI å…¼å®¹æ¨¡å¼ï¼‰
	// Ollama é»˜è®¤åœ¨ localhost:11434 è¿è¡Œï¼ŒOpenAI å…¼å®¹æŽ¥å£åœ¨ /v1
	model, err := openai.New(
		openai.WithBaseURL("http://localhost:11434/v1"),
		openai.WithModel("deepseek-r1:14b"),
		openai.WithToken("ollama"), // Ollama ä¸éœ€è¦çœŸå®ž token
	)
	if err != nil {
		fmt.Printf("âŒ åˆ›å»ºæ¨¡åž‹å¤±è´¥: %v\n", err)
		fmt.Println("è¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ: ollama serve")
		return
	}

	// åˆ›å»ºå¯¹è¯å›¾ï¼ˆä½¿ç”¨æ³›åž‹ï¼‰
	g := graph.NewStateGraph[ChatState]()

	// æ·»åŠ å¯¹è¯èŠ‚ç‚¹
	g.AddNode("chat", "ä¸Ž DeepSeek å¯¹è¯", func(ctx context.Context, state ChatState) (ChatState, error) {
		messages := state.Messages

		fmt.Print("ðŸ¤– DeepSeek æ€è€ƒä¸­...")

		// è°ƒç”¨æ¨¡åž‹ç”Ÿæˆå›žå¤
		response, err := model.GenerateContent(ctx, messages,
			llms.WithTemperature(0.7),
			llms.WithMaxTokens(2000),
		)
		if err != nil {
			return ChatState{Messages: []llms.MessageContent{}}, err
		}

		fmt.Print("\r")

		// æå–å›žå¤å†…å®¹
		aiResponse := response.Choices[0].Content

		// è¿”å›žæ›´æ–°åŽçš„çŠ¶æ€
		newMessages := append(messages, llms.TextParts(llms.ChatMessageTypeAI, aiResponse))
		return ChatState{Messages: newMessages}, nil
	})

	// è®¾ç½®å›¾ç»“æž„
	g.AddEdge("chat", graph.END)
	g.SetEntryPoint("chat")

	// ç¼–è¯‘å›¾
	runnable, err := g.Compile()
	if err != nil {
		panic(err)
	}

	// åˆå§‹åŒ–å¯¹è¯çŠ¶æ€
	chatState := ChatState{
		Messages: []llms.MessageContent{},
	}

	// äº¤äº’å¼å¯¹è¯å¾ªçŽ¯
	scanner := bufio.NewScanner(os.Stdin)
	ctx := context.Background()

	for {
		fmt.Print("ðŸ‘¤ ä½ : ")
		if !scanner.Scan() {
			break
		}

		userInput := strings.TrimSpace(scanner.Text())

		// æ£€æŸ¥é€€å‡ºå‘½ä»¤
		if userInput == "quit" || userInput == "exit" || userInput == "" {
			fmt.Println("ðŸ‘‹ å†è§ï¼")
			break
		}

		// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°çŠ¶æ€
		chatState.Messages = append(chatState.Messages,
			llms.TextParts(llms.ChatMessageTypeHuman, userInput))

		// æ‰§è¡Œå¯¹è¯
		result, err := runnable.Invoke(ctx, chatState)
		if err != nil {
			fmt.Printf("âŒ é”™è¯¯: %v\n", err)
			continue
		}

		// æ›´æ–°å¯¹è¯çŠ¶æ€
		chatState = result

		// æ˜¾ç¤º AI å›žå¤
		lastMessage := chatState.Messages[len(chatState.Messages)-1]
		if len(lastMessage.Parts) > 0 {
			if textPart, ok := lastMessage.Parts[0].(llms.TextContent); ok {
				fmt.Printf("ðŸ¤– DeepSeek: %s\n\n", textPart.Text)
			}
		}
	}
}
