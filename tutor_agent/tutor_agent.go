package tutor_agent

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"github.com/smallnest/langgraphgo/graph"
	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/openai"
)

// For test: /Users/wangyang/gitclonefiles/datafusion/README.md

type LLMType int

const (
	OpenAI LLMType = iota
	Ollama
)

// Tutor agent state definition
type TutorState struct {
	// Documents contents
	DocumentContents map[string]string
	// Generated by the Agent
	DocumentSummary string
	// Chat history
	Messages []llms.MessageContent
	// User input
	UserInput string
	// Whether the agent should continue
	ShouldContinue bool
	// Current teaching stage
	Stage string
}

type TutorAgent struct {
	model   llms.Model
	graph   *graph.StateRunnable[TutorState]
	scanner *bufio.Scanner
}

func NewTutorAgent(llmType LLMType) (*TutorAgent, error) {
	switch llmType {
	case OpenAI:
		return nil, errors.New("unsupported LLM type: OpenAI")
	case Ollama:
		return newOllamaTutorAgent()
	default:
		return nil, errors.New(fmt.Sprintf("unrecognized LLM type: %d", llmType))
	}
}

func newOllamaTutorAgent() (*TutorAgent, error) {
	// Config Ollama
	model, err := openai.New(
		openai.WithBaseURL("http://localhost:11434/v1"),
		openai.WithModel("deepseek-r1:14b"),
		openai.WithToken("ollama"),
	)
	if err != nil {
		return nil, fmt.Errorf("create LLM failed: %v", err)
	}

	agent := &TutorAgent{
		model:   model,
		scanner: bufio.NewScanner(os.Stdin),
	}

	if err := agent.buildGraph(); err != nil {
		return nil, err
	}

	return agent, nil
}

func (t *TutorAgent) buildGraph() error {
	g := graph.NewStateGraph[TutorState]()

	// 1. Load documents node
	g.AddNode("load_documents", "load documents", t.loadDocuments)

	// 2. Analyze documents node
	g.AddNode("analyze_documents", "analyze documents", t.analyzeDocuments)

	// 3. Chat node
	g.AddNode("chat", "chat", t.chat)

	// 4. Check continue node, no need the continue check again
	// g.AddNode("check_continue", "check continue", t.checkContinue)

	// Set edges
	g.AddEdge("load_documents", "analyze_documents")
	g.AddEdge("analyze_documents", "chat")

	// no need the check continue node anymore
	// g.AddEdge("chat", "check_continue")

	// Conditional edge: decide the flow based on whether the user wants to continue
	g.AddConditionalEdge("chat", func(ctx context.Context, state TutorState) string {
		if state.ShouldContinue {
			return "chat" // continue chatting
		}
		return graph.END // end the session
	})

	// Set entry point
	g.SetEntryPoint("load_documents")

	// Compile the graph
	runnable, err := g.Compile()
	if err != nil {
		return err
	}

	t.graph = runnable
	return nil
}

func (t *TutorAgent) loadDocuments(ctx context.Context, state TutorState) (TutorState, error) {
	fmt.Println("\nğŸ“š === æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿ ===")
	fmt.Println("æˆ‘å¯ä»¥å¸®åŠ©ä½ æ·±å…¥å­¦ä¹ å’Œç†è§£æ–‡æ¡£å†…å®¹ï¼")
	fmt.Println()

	// è·å–æ–‡ä»¶è·¯å¾„
	fmt.Print("è¯·è¾“å…¥è¦å­¦ä¹ çš„æ–‡æ¡£è·¯å¾„ï¼ˆå¤šä¸ªæ–‡ä»¶ç”¨é€—å·åˆ†éš”ï¼‰: ")
	if !t.scanner.Scan() {
		return state, fmt.Errorf("è¯»å–è¾“å…¥å¤±è´¥")
	}

	pathsInput := strings.TrimSpace(t.scanner.Text())
	if pathsInput == "" {
		return state, fmt.Errorf("æœªæä¾›æ–‡æ¡£è·¯å¾„")
	}

	// è§£æè·¯å¾„
	paths := strings.Split(pathsInput, ",")
	state.DocumentContents = make(map[string]string)

	// åŠ è½½æ¯ä¸ªæ–‡ä»¶
	for _, path := range paths {
		path = strings.TrimSpace(path)
		content, err := t.loadFile(path)
		if err != nil {
			fmt.Printf("âš ï¸  åŠ è½½æ–‡ä»¶ %s å¤±è´¥: %v\n", path, err)
			continue
		}
		state.DocumentContents[path] = content
		fmt.Printf("âœ… å·²åŠ è½½: %s (%d å­—ç¬¦)\n", filepath.Base(path), len(content))
	}

	if len(state.DocumentContents) == 0 {
		return state, fmt.Errorf("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£")
	}

	state.Stage = "documents_loaded"
	return state, nil
}

// loadFile åŠ è½½å•ä¸ªæ–‡ä»¶
func (t *TutorAgent) loadFile(path string) (string, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return "", err
	}
	return string(data), nil
}

// analyzeDocuments ä½¿ç”¨ AI åˆ†ææ–‡æ¡£å†…å®¹
func (t *TutorAgent) analyzeDocuments(ctx context.Context, state TutorState) (TutorState, error) {
	fmt.Println("\nğŸ” æ­£åœ¨åˆ†ææ–‡æ¡£å†…å®¹...")

	// âš ï¸âš ï¸âš ï¸ ã€æ–°å¢ã€‘è®¡ç®—æ€»å­—ç¬¦æ•°ï¼Œç”¨äºæ˜¾ç¤ºè¿›åº¦ âš ï¸âš ï¸âš ï¸
	totalChars := 0
	for _, content := range state.DocumentContents {
		totalChars += len(content)
	}

	// æ„å»ºæ–‡æ¡£å†…å®¹æ‘˜è¦
	var docsBuilder strings.Builder
	docsBuilder.WriteString("ä»¥ä¸‹æ˜¯éœ€è¦å­¦ä¹ çš„æ–‡æ¡£å†…å®¹ï¼š\n\n")

	// âš ï¸âš ï¸âš ï¸ ã€æ–°å¢ã€‘æ·»åŠ è¿›åº¦è·Ÿè¸ª âš ï¸âš ï¸âš ï¸
	processedChars := 0
	fileCount := 0
	totalFiles := len(state.DocumentContents)

	for path, content := range state.DocumentContents {
		fileCount++
		fmt.Printf("ğŸ“„ å¤„ç†æ–‡ä»¶ [%d/%d]: %s\n", fileCount, totalFiles, filepath.Base(path))

		docsBuilder.WriteString(fmt.Sprintf("=== æ–‡ä»¶: %s ===\n", filepath.Base(path)))

		// å¦‚æœæ–‡æ¡£å¤ªé•¿ï¼Œæˆªå–å‰é¢éƒ¨åˆ†
		contentToAdd := content
		if len(content) > 8000 {
			contentToAdd = content[:8000]
			docsBuilder.WriteString(contentToAdd)
			docsBuilder.WriteString("\n\n[æ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ 8000 å­—ç¬¦]\n\n")
		} else {
			docsBuilder.WriteString(contentToAdd)
			docsBuilder.WriteString("\n\n")
		}

		// âš ï¸âš ï¸âš ï¸ ã€æ–°å¢ã€‘æ›´æ–°å¹¶æ˜¾ç¤ºè¿›åº¦ âš ï¸âš ï¸âš ï¸
		processedChars += len(content)
		progress := float64(processedChars) / float64(totalChars) * 100
		fmt.Printf("   â³ åŠ è½½è¿›åº¦: %.1f%% (%d/%d å­—ç¬¦)\n", progress, processedChars, totalChars)
	}

	fmt.Println("\nâœ… æ–‡ä»¶åŠ è½½å®Œæˆï¼Œæ­£åœ¨æäº¤ç»™åŠ©æ•™åˆ†æ...")

	// è®© AI åˆ†ææ–‡æ¡£
	analysisPrompt := docsBuilder.String() + `

è¯·ä½œä¸ºä¸€ä½ä¸“ä¸šçš„åŠ©æ•™ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. ç®€è¦æ¦‚è¿°è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹å’Œæ ¸å¿ƒæ¦‚å¿µ
2. åˆ—å‡ºæ–‡æ¡£ä¸­çš„é‡ç‚¹çŸ¥è¯†ç‚¹
3. è¯´æ˜ä½ å°†å¦‚ä½•å¸®åŠ©å­¦ä¹ è€…ç†è§£è¿™äº›å†…å®¹

è¯·ç”¨å‹å¥½ã€æ˜“æ‡‚çš„è¯­è¨€å›å¤ã€‚`

	messages := []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeHuman, analysisPrompt),
	}

	fmt.Println() // æ¢è¡Œï¼Œè®©è¾“å‡ºæ›´æ¸…æ™°
	fmt.Println("ğŸ¤– åŠ©æ•™æ­£åœ¨æ·±åº¦åˆ†ææ–‡æ¡£...")
	fmt.Println(strings.Repeat("-", 60))

	var summaryBuilder strings.Builder
	var isThinking bool

	// âš ï¸âš ï¸âš ï¸ ã€æ–°å¢ã€‘æ·»åŠ å­—ç¬¦è®¡æ•°ï¼Œç”¨äºæ˜¾ç¤ºåˆ†æè¿›åº¦ âš ï¸âš ï¸âš ï¸
	var charCount int

	response, err := t.model.GenerateContent(ctx, messages,
		llms.WithTemperature(0.7),
		llms.WithMaxTokens(2000),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			text := string(chunk)

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹æ ‡è®°
			if strings.Contains(text, "<think>") {
				isThinking = true
				fmt.Print("ğŸ’­ åŠ©æ•™æ€è€ƒ: ")
				return nil
			}
			if strings.Contains(text, "</think>") {
				isThinking = false
				fmt.Println("\n")
				return nil
			}

			// è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–æœ€ç»ˆå†…å®¹
			if isThinking {
				fmt.Print(text)
			} else {
				// è¿‡æ»¤æ‰æ ‡ç­¾
				cleanText := strings.ReplaceAll(text, "<think>", "")
				cleanText = strings.ReplaceAll(cleanText, "</think>", "")
				if cleanText != "" {
					summaryBuilder.WriteString(cleanText)
					// âš ï¸âš ï¸âš ï¸ ã€æ–°å¢ã€‘å®æ—¶æ˜¾ç¤ºç”Ÿæˆçš„å­—ç¬¦æ•° âš ï¸âš ï¸âš ï¸
					charCount += len(cleanText)
					fmt.Print(cleanText)
				}
			}

			return nil
		}),
	)
	if err != nil {
		return state, fmt.Errorf("åˆ†ææ–‡æ¡£å¤±è´¥: %v", err)
	}

	// å¦‚æœæœ‰æµå¼è¾“å‡ºï¼Œä½¿ç”¨ summaryBuilder çš„å†…å®¹ï¼Œå¦åˆ™ä½¿ç”¨ response
	if summaryBuilder.Len() > 0 {
		state.DocumentSummary = summaryBuilder.String()
	} else {
		state.DocumentSummary = response.Choices[0].Content
	}

	// state.DocumentSummary = response.Choices[0].Content

	// åˆå§‹åŒ–å¯¹è¯å†å²ï¼ŒåŒ…å«æ–‡æ¡£å†…å®¹å’Œæ¦‚è¿°
	state.Messages = []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeSystem,
			fmt.Sprintf(`ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ©æ•™ï¼Œå¸®åŠ©å­¦ä¹ è€…æ·±å…¥ç†è§£ä»¥ä¸‹æ–‡æ¡£å†…å®¹ã€‚

%s

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. å›ç­”å­¦ä¹ è€…å…³äºæ–‡æ¡£å†…å®¹çš„é—®é¢˜
2. æä¾›æ·±å…¥çš„è§£é‡Šå’Œç¤ºä¾‹
3. å¼•å¯¼å­¦ä¹ è€…æ€è€ƒå’Œæ¢ç´¢
4. ç”¨æ¸…æ™°ã€å‹å¥½çš„è¯­è¨€äº¤æµ

è¯·åŸºäºæ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼Œå¦‚æœéœ€è¦ä¸¾ä¾‹è¯´æ˜ï¼Œå¯ä»¥ä»æ–‡æ¡£ä¸­æå–ç›¸å…³å†…å®¹ã€‚`, docsBuilder.String())),
		llms.TextParts(llms.ChatMessageTypeAI, state.DocumentSummary),
	}

	// âš ï¸âš ï¸âš ï¸ ã€ä¿®æ”¹ã€‘ä¼˜åŒ–è¾“å‡ºæ ¼å¼ âš ï¸âš ï¸âš ï¸
	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Printf("âœ… åˆ†æå®Œæˆï¼ç”Ÿæˆäº† %d å­—ç¬¦çš„åˆ†ææŠ¥å‘Š\n", len(state.DocumentSummary))
	fmt.Println(strings.Repeat("=", 60))
	fmt.Println("\nğŸ’¡ æç¤ºï¼šè¾“å…¥ 'quit' æˆ– 'exit' å¯ä»¥é€€å‡º")

	state.Stage = "analysis_complete"
	state.ShouldContinue = true
	return state, nil
}

// chat å¯¹è¯äº¤äº’ - æ”¯æŒå¤šè½®å¯¹è¯
func (t *TutorAgent) chat(ctx context.Context, state TutorState) (TutorState, error) {
	// è·å–ç”¨æˆ·è¾“å…¥
	fmt.Print("\nğŸ’¬ ä½ çš„é—®é¢˜: ")
	if !t.scanner.Scan() {
		state.ShouldContinue = false
		return state, nil
	}

	userInput := strings.TrimSpace(t.scanner.Text())
	state.UserInput = userInput

	// æ£€æŸ¥é€€å‡ºå‘½ä»¤
	if userInput == "quit" || userInput == "exit" {
		state.ShouldContinue = false
		fmt.Println("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿï¼ç¥å­¦ä¹ æ„‰å¿«ï¼")
		return state, nil
	}

	// å¦‚æœç”¨æˆ·ç›´æ¥å›è½¦ï¼ˆç©ºè¾“å…¥ï¼‰ï¼Œæç¤ºé‡æ–°è¾“å…¥
	if userInput == "" {
		fmt.Println("âš ï¸  è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥ 'quit'/'exit' é€€å‡º")
		state.ShouldContinue = true
		return state, nil
	}

	// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeHuman, userInput))

	// ä¿®æ”¹ä¸ºï¼š
	fmt.Println() // æ¢è¡Œ

	var responseBuilder strings.Builder
	var isThinking bool
	var hasStartedOutput bool

	response, err := t.model.GenerateContent(ctx, state.Messages,
		llms.WithTemperature(0.7),
		llms.WithMaxTokens(3000),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			text := string(chunk)

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„å¼€å§‹æ ‡è®°
			if strings.Contains(text, "<think>") {
				isThinking = true
				fmt.Print("ğŸ’­ åŠ©æ•™æ€è€ƒ: ")
				hasStartedOutput = true
				return nil
			}

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„ç»“æŸæ ‡è®°
			if strings.Contains(text, "</think>") {
				isThinking = false
				fmt.Println("\n")
				fmt.Print("ğŸ“ åŠ©æ•™: ")
				return nil
			}

			// è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–æœ€ç»ˆç­”æ¡ˆ
			if isThinking {
				// æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆè¿‡æ»¤æ ‡ç­¾ï¼‰
				cleanText := strings.ReplaceAll(text, "<think>", "")
				fmt.Print(cleanText)
			} else {
				// è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
				if !hasStartedOutput {
					fmt.Print("ğŸ“ åŠ©æ•™: ")
					hasStartedOutput = true
				}
				// è¿‡æ»¤æ ‡ç­¾
				cleanText := strings.ReplaceAll(text, "</think>", "")
				if cleanText != "" {
					fmt.Print(cleanText)
					responseBuilder.WriteString(cleanText)
				}
			}

			return nil
		}),
	)
	if err != nil {
		fmt.Printf("\nâŒ ç”Ÿæˆå›å¤å¤±è´¥: %v\n", err)
		// å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­å¯¹è¯
		state.ShouldContinue = true
		return state, nil
	}

	fmt.Println() // å›å¤ç»“æŸåæ¢è¡Œç¤º

	// è·å– AI å›å¤å†…å®¹
	var aiResponse string
	if responseBuilder.Len() > 0 {
		aiResponse = responseBuilder.String()
	} else {
		aiResponse = response.Choices[0].Content
	}

	// æ·»åŠ  AI å›å¤åˆ°å†å²
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeAI, aiResponse))

	// ç»§ç»­å¯¹è¯å¾ªç¯
	state.ShouldContinue = true
	state.Stage = "chat_complete"
	return state, nil
}

// Run è¿è¡ŒåŠ©æ•™ç³»ç»Ÿ
func (t *TutorAgent) Run() error {
	ctx := context.Background()

	// åˆå§‹åŒ–çŠ¶æ€
	initialState := TutorState{
		DocumentContents: make(map[string]string),
		Messages:         []llms.MessageContent{},
		ShouldContinue:   true,
		Stage:            "init",
	}

	// æ‰§è¡Œå·¥ä½œæµ
	// âš ï¸âš ï¸âš ï¸ ã€ä¿®æ”¹4ã€‘åˆ é™¤ finalState å˜é‡ï¼Œä¸å†éœ€è¦åœ¨è¿™é‡Œæ˜¾ç¤ºé€€å‡ºæ¶ˆæ¯ âš ï¸âš ï¸âš ï¸
	// åŸä»£ç ï¼šfinalState, err := t.graph.Invoke(ctx, initialState)
	// ä¿®æ”¹ä¸ºï¼š
	_, err := t.graph.Invoke(ctx, initialState)
	if err != nil {
		return fmt.Errorf("æ‰§è¡Œå¤±è´¥: %v", err)
	}

	// âš ï¸âš ï¸âš ï¸ ã€ä¿®æ”¹5ã€‘åˆ é™¤è¿™é‡Œçš„é€€å‡ºæ¶ˆæ¯ï¼Œå·²ç»åœ¨ chat() å‡½æ•°ä¸­æ˜¾ç¤º âš ï¸âš ï¸âš ï¸
	// åŸä»£ç ï¼š
	// if finalState.Stage != "init" {
	// 	fmt.Println("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿï¼ç¥å­¦ä¹ æ„‰å¿«ï¼")
	// }
	// åˆ é™¤ä¸Šè¿°ä»£ç 

	return nil
}
