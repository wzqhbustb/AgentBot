package tutor_agent

import (
	"bufio"
	"context"
	"errors"
	"fmt"
	"math"
	"ollama-demo/hnsw"
	"os"
	"path/filepath"
	"strings"

	"github.com/smallnest/langgraphgo/graph"
	"github.com/tmc/langchaingo/embeddings"
	"github.com/tmc/langchaingo/llms"
	"github.com/tmc/langchaingo/llms/openai"
)

// For test: /Users/wangyang/gitclonefiles/datafusion/README.md

type LLMType int

const (
	OpenAI LLMType = iota
	Ollama
)

type DocumentChunk struct {
	Content  string            // åˆ‡ç‰‡å†…å®¹
	Source   string            // æ¥æºæ–‡ä»¶
	ChunkID  int               // åˆ‡ç‰‡ID
	Metadata map[string]string // å…ƒæ•°æ®
}

// Tutor agent state definition
type TutorState struct {
	// Documents contents
	DocumentContents map[string]string

	// Document chunks and vector index
	DocumentChunks []DocumentChunk

	// HNSW Vector Index
	VectorIndex *hnsw.HNSWIndex

	// Embedding model
	Embedder embeddings.Embedder

	// æ–°å¢ï¼šNodeID åˆ° Chunk ç´¢å¼•çš„æ˜ å°„
	NodeIDToChunkIndex map[int]int

	// Generated by the Agent
	DocumentSummary string

	// Chat history
	Messages []llms.MessageContent

	// User input
	UserInput string

	// Whether the agent should continue
	ShouldContinue bool

	// Current teaching stage
	Stage string
}

type TutorAgent struct {
	model     llms.Model
	embedder  embeddings.Embedder
	graph     *graph.StateRunnable[TutorState]
	scanner   *bufio.Scanner
	dimension int // Embedding dimension
}

func NewTutorAgent(llmType LLMType) (*TutorAgent, error) {
	switch llmType {
	case OpenAI:
		return nil, errors.New("unsupported LLM type: OpenAI")
	case Ollama:
		return newOllamaTutorAgent()
	default:
		return nil, errors.New(fmt.Sprintf("unrecognized LLM type: %d", llmType))
	}
}

func newOllamaTutorAgent() (*TutorAgent, error) {
	// Config Ollama
	model, err := openai.New(
		openai.WithBaseURL("http://localhost:11434/v1"),
		openai.WithModel("deepseek-r1:14b"),
		openai.WithToken("ollama"),
	)
	if err != nil {
		return nil, fmt.Errorf("create LLM failed: %v", err)
	}

	embeddingLLM, err := openai.New(
		openai.WithBaseURL("http://localhost:11434/v1"),
		openai.WithToken("ollama"),
		openai.WithModel("nomic-embed-text"),
		openai.WithEmbeddingModel("nomic-embed-text"),
	)
	if err != nil {
		return nil, fmt.Errorf("create embedding LLM failed: %v", err)
	}

	embedder, err := embeddings.NewEmbedder(embeddingLLM)
	if err != nil {
		return nil, fmt.Errorf("create embedder failed: %v", err)
	}

	agent := &TutorAgent{
		model:     model,
		embedder:  embedder, // åˆå§‹åŒ– embedder
		scanner:   bufio.NewScanner(os.Stdin),
		dimension: 768, // nomic-embed-text çš„ç»´åº¦æ˜¯ 768
	}

	if err := agent.buildGraph(); err != nil {
		return nil, err
	}

	return agent, nil
}

func (t *TutorAgent) buildGraph() error {
	g := graph.NewStateGraph[TutorState]()

	// 1. Load documents node
	g.AddNode("load_documents", "load documents", t.loadDocuments)

	g.AddNode("vectorize_documents", "vectorize documents", t.vectorizeDocuments)

	// 2. Analyze documents node
	g.AddNode("analyze_documents", "analyze documents", t.analyzeDocuments)

	// 3. Chat node
	g.AddNode("chat", "chat", t.chatWithRAG)

	// Set edges
	g.AddEdge("load_documents", "vectorize_documents")    // æ”¹ä¸ºå…ˆå‘é‡åŒ–
	g.AddEdge("vectorize_documents", "analyze_documents") // å‘é‡åŒ–åå†åˆ†æ
	g.AddEdge("analyze_documents", "chat")

	// no need the check continue node anymore
	// g.AddEdge("chat", "check_continue")

	// Conditional edge: decide the flow based on whether the user wants to continue
	g.AddConditionalEdge("chat", func(ctx context.Context, state TutorState) string {
		if state.ShouldContinue {
			return "chat" // continue chatting
		}
		return graph.END // end the session
	})

	// Set entry point
	g.SetEntryPoint("load_documents")

	// Compile the graph
	runnable, err := g.Compile()
	if err != nil {
		return err
	}

	t.graph = runnable
	return nil
}

func (t *TutorAgent) loadDocuments(ctx context.Context, state TutorState) (TutorState, error) {
	fmt.Println("\nğŸ“š === æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿï¼ˆRAG å¢å¼ºç‰ˆï¼‰===") // âœ¨ ä¿®æ”¹ï¼šæ ‡é¢˜åŠ ä¸Š RAG æ ‡è¯†
	fmt.Println("æˆ‘å¯ä»¥å¸®åŠ©ä½ æ·±å…¥å­¦ä¹ å’Œç†è§£æ–‡æ¡£å†…å®¹ï¼")
	fmt.Println("ğŸ’¡ ä½¿ç”¨å‘é‡æœç´¢æŠ€æœ¯ï¼Œç²¾å‡†æ£€ç´¢ç›¸å…³å†…å®¹") // âœ¨ æ–°å¢ï¼šæç¤º RAG åŠŸèƒ½
	fmt.Println()

	// è·å–æ–‡ä»¶è·¯å¾„
	fmt.Print("è¯·è¾“å…¥è¦å­¦ä¹ çš„æ–‡æ¡£è·¯å¾„ï¼ˆå¤šä¸ªæ–‡ä»¶ç”¨é€—å·åˆ†éš”ï¼‰: ")
	if !t.scanner.Scan() {
		return state, fmt.Errorf("è¯»å–è¾“å…¥å¤±è´¥")
	}

	pathsInput := strings.TrimSpace(t.scanner.Text())
	if pathsInput == "" {
		return state, fmt.Errorf("æœªæä¾›æ–‡æ¡£è·¯å¾„")
	}

	// è§£æè·¯å¾„
	paths := strings.Split(pathsInput, ",")
	state.DocumentContents = make(map[string]string)

	// åŠ è½½æ¯ä¸ªæ–‡ä»¶
	for _, path := range paths {
		path = strings.TrimSpace(path)
		content, err := t.loadFile(path)
		if err != nil {
			fmt.Printf("âš ï¸  åŠ è½½æ–‡ä»¶ %s å¤±è´¥: %v\n", path, err)
			continue
		}
		state.DocumentContents[path] = content
		fmt.Printf("âœ… å·²åŠ è½½: %s (%d å­—ç¬¦)\n", filepath.Base(path), len(content))
	}

	if len(state.DocumentContents) == 0 {
		return state, fmt.Errorf("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡æ¡£")
	}

	state.Stage = "documents_loaded"
	state.Embedder = t.embedder // âœ¨ æ–°å¢ï¼šå°† embedder å­˜å…¥ state
	return state, nil
}

// loadFile åŠ è½½å•ä¸ªæ–‡ä»¶
func (t *TutorAgent) loadFile(path string) (string, error) {
	data, err := os.ReadFile(path)
	if err != nil {
		return "", err
	}
	return string(data), nil
}

// chunkText - æ–‡æ¡£åˆ‡å—
func (t *TutorAgent) chunkText(text string, chunkSize int, overlap int) []string {
	// æŒ‰æ®µè½åˆ†å‰²
	paragraphs := strings.Split(text, "\n\n")

	var chunks []string
	var currentChunk strings.Builder
	currentSize := 0

	for _, para := range paragraphs {
		para = strings.TrimSpace(para)
		if para == "" {
			continue
		}

		paraSize := len(para)

		// å¦‚æœå½“å‰æ®µè½åŠ ä¸Šå·²æœ‰å†…å®¹è¶…è¿‡ chunkSizeï¼Œä¿å­˜å½“å‰ chunk
		if currentSize > 0 && currentSize+paraSize > chunkSize {
			chunks = append(chunks, currentChunk.String())

			// ä¿ç•™ overlap éƒ¨åˆ†
			chunkText := currentChunk.String()
			if len(chunkText) > overlap {
				currentChunk.Reset()
				currentChunk.WriteString(chunkText[len(chunkText)-overlap:])
				currentChunk.WriteString("\n\n")
				currentSize = overlap
			} else {
				currentChunk.Reset()
				currentSize = 0
			}
		}

		currentChunk.WriteString(para)
		currentChunk.WriteString("\n\n")
		currentSize += paraSize
	}

	// æ·»åŠ æœ€åä¸€ä¸ª chunk
	if currentSize > 0 {
		chunks = append(chunks, currentChunk.String())
	}

	return chunks
}

// vectorizeDocuments - å‘é‡åŒ–æ–‡æ¡£
func (t *TutorAgent) vectorizeDocuments(ctx context.Context, state TutorState) (TutorState, error) {
	fmt.Println("\nğŸ”„ æ­£åœ¨å¤„ç†æ–‡æ¡£...")

	// åˆ›å»º HNSW ç´¢å¼•
	state.VectorIndex = hnsw.NewHNSW(hnsw.Config{
		M:              16,
		EfConstruction: 200,
		Dimension:      t.dimension,
		DistanceFunc:   hnsw.CosineDistance, // ä½¿ç”¨ä½™å¼¦è·ç¦»
	})
	fmt.Printf("âœ… åˆ›å»ºå‘é‡ç´¢å¼• (dimension=%d)\n", t.dimension)

	// åˆ‡å—å‚æ•°
	chunkSize := 500 // æ¯å—çº¦ 500 å­—ç¬¦
	overlap := 50    // é‡å  50 å­—ç¬¦

	state.DocumentChunks = []DocumentChunk{}
	// æ–°å¢ï¼šåˆ›å»º NodeID åˆ° Chunk ç´¢å¼•çš„æ˜ å°„
	nodeIDToChunkIndex := make(map[int]int) //
	chunkID := 0

	// å¤„ç†æ¯ä¸ªæ–‡æ¡£
	for path, content := range state.DocumentContents {
		fmt.Printf("\nğŸ“„ å¤„ç†æ–‡æ¡£: %s\n", filepath.Base(path))

		// åˆ‡åˆ†æ–‡æ¡£
		chunks := t.chunkText(content, chunkSize, overlap)
		fmt.Printf("   åˆ‡åˆ†ä¸º %d ä¸ªå—\n", len(chunks))

		// å‘é‡åŒ–æ¯ä¸ªå—
		for i, chunkText := range chunks {
			// ç”Ÿæˆ embedding
			vector, err := state.Embedder.EmbedQuery(ctx, chunkText)
			if err != nil {
				fmt.Printf("âš ï¸  å— %d å‘é‡åŒ–å¤±è´¥: %v\n", i, err)
				continue
			}

			// è½¬æ¢ä¸º float32
			vector32 := make([]float32, len(vector))
			for j, v := range vector {
				vector32[j] = float32(v)
			}

			// æ·»åŠ åˆ° HNSW ç´¢å¼•
			nodeID, err := state.VectorIndex.Add(vector32)
			if err != nil {
				fmt.Printf("âš ï¸  å— %d æ·»åŠ åˆ°ç´¢å¼•å¤±è´¥: %v\n", i, err)
				continue
			}

			// è®°å½•æ˜ å°„å…³ç³»
			chunkIndex := len(state.DocumentChunks)
			nodeIDToChunkIndex[nodeID] = chunkIndex

			// ä¿å­˜å—ä¿¡æ¯
			chunk := DocumentChunk{
				Content: chunkText,
				Source:  filepath.Base(path),
				ChunkID: chunkID,
				Metadata: map[string]string{
					"source": filepath.Base(path),
					"nodeID": fmt.Sprintf("%d", nodeID),
				},
			}
			state.DocumentChunks = append(state.DocumentChunks, chunk)
			chunkID++

			if (i+1)%10 == 0 || i == len(chunks)-1 {
				fmt.Printf("   è¿›åº¦: %d/%d å—å·²å‘é‡åŒ–\n", i+1, len(chunks))
			}
		}
	}

	// åœ¨è¿”å›å‰ä¿å­˜æ˜ å°„è¡¨
	state.NodeIDToChunkIndex = nodeIDToChunkIndex

	fmt.Printf("\nâœ… å‘é‡åŒ–å®Œæˆï¼æ€»å…±å¤„ç† %d ä¸ªæ–‡æ¡£å—\n", len(state.DocumentChunks))
	state.Stage = "vectorization_complete"
	return state, nil
}

// analyzeDocuments ä½¿ç”¨ AI åˆ†ææ–‡æ¡£å†…å®¹
func (t *TutorAgent) analyzeDocuments(ctx context.Context, state TutorState) (TutorState, error) {
	fmt.Println("\nğŸ” æ­£åœ¨åˆ†ææ–‡æ¡£å†…å®¹...")
	totalChars := 0
	for _, content := range state.DocumentContents {
		totalChars += len(content)
	}

	// æ„å»ºæ–‡æ¡£å†…å®¹æ‘˜è¦
	var docsBuilder strings.Builder
	docsBuilder.WriteString("ä»¥ä¸‹æ˜¯éœ€è¦å­¦ä¹ çš„æ–‡æ¡£å†…å®¹ï¼š\n\n")

	processedChars := 0
	fileCount := 0
	totalFiles := len(state.DocumentContents)

	for path, content := range state.DocumentContents {
		fileCount++
		fmt.Printf("ğŸ“„ å¤„ç†æ–‡ä»¶ [%d/%d]: %s\n", fileCount, totalFiles, filepath.Base(path))

		docsBuilder.WriteString(fmt.Sprintf("=== æ–‡ä»¶: %s ===\n", filepath.Base(path)))

		// å¦‚æœæ–‡æ¡£å¤ªé•¿ï¼Œæˆªå–å‰é¢éƒ¨åˆ†
		contentToAdd := content
		if len(content) > 2000 {
			contentToAdd = content[:2000]
			docsBuilder.WriteString(contentToAdd)
			docsBuilder.WriteString("\n\n[æ–‡æ¡£å†…å®¹è¿‡é•¿ï¼Œå·²æˆªå–å‰ 2000 å­—ç¬¦]\n\n")
		} else {
			docsBuilder.WriteString(contentToAdd)
			docsBuilder.WriteString("\n\n")
		}

		processedChars += len(content)
		progress := float64(processedChars) / float64(totalChars) * 100
		fmt.Printf("   â³ åŠ è½½è¿›åº¦: %.1f%% (%d/%d å­—ç¬¦)\n", progress, processedChars, totalChars)
	}

	fmt.Println("\nâœ… æ–‡ä»¶åŠ è½½å®Œæˆï¼Œæ­£åœ¨æäº¤ç»™åŠ©æ•™åˆ†æ...")

	// è®© AI åˆ†ææ–‡æ¡£
	analysisPrompt := docsBuilder.String() + fmt.Sprintf(`

æ–‡æ¡£å·²è¢«åˆ‡åˆ†ä¸º %d ä¸ªå—å¹¶å‘é‡åŒ–ï¼Œæ”¯æŒæ™ºèƒ½æ£€ç´¢ã€‚

è¯·ä½œä¸ºä¸€ä½ä¸“ä¸šçš„åŠ©æ•™ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. ç®€è¦æ¦‚è¿°è¿™äº›æ–‡æ¡£çš„ä¸»è¦å†…å®¹å’Œæ ¸å¿ƒæ¦‚å¿µ
2. åˆ—å‡ºæ–‡æ¡£ä¸­çš„é‡ç‚¹çŸ¥è¯†ç‚¹
3. è¯´æ˜ä½ å°†å¦‚ä½•å¸®åŠ©å­¦ä¹ è€…ç†è§£è¿™äº›å†…å®¹

è¯·ç”¨å‹å¥½ã€æ˜“æ‡‚çš„è¯­è¨€å›å¤ã€‚`, len(state.DocumentChunks))

	messages := []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeHuman, analysisPrompt),
	}

	fmt.Println() // æ¢è¡Œï¼Œè®©è¾“å‡ºæ›´æ¸…æ™°
	fmt.Println("ğŸ¤– åŠ©æ•™æ­£åœ¨æ·±åº¦åˆ†ææ–‡æ¡£...")
	fmt.Println(strings.Repeat("-", 60))

	var summaryBuilder strings.Builder
	var isThinking bool
	var charCount int

	response, err := t.model.GenerateContent(ctx, messages,
		llms.WithTemperature(0.7),
		llms.WithMaxTokens(2000),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			text := string(chunk)

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹æ ‡è®°
			if strings.Contains(text, "<think>") {
				isThinking = true
				fmt.Print("ğŸ’­ åŠ©æ•™æ€è€ƒ: ")
				return nil
			}
			if strings.Contains(text, "</think>") {
				isThinking = false
				fmt.Println("")
				return nil
			}

			// è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–æœ€ç»ˆå†…å®¹
			if isThinking {
				fmt.Print(text)
			} else {
				// è¿‡æ»¤æ‰æ ‡ç­¾
				cleanText := strings.ReplaceAll(text, "<think>", "")
				cleanText = strings.ReplaceAll(cleanText, "</think>", "")
				if cleanText != "" {
					summaryBuilder.WriteString(cleanText)
					charCount += len(cleanText)
					fmt.Print(cleanText)
				}
			}

			return nil
		}),
	)
	if err != nil {
		return state, fmt.Errorf("åˆ†ææ–‡æ¡£å¤±è´¥: %v", err)
	}

	// å¦‚æœæœ‰æµå¼è¾“å‡ºï¼Œä½¿ç”¨ summaryBuilder çš„å†…å®¹ï¼Œå¦åˆ™ä½¿ç”¨ response
	if summaryBuilder.Len() > 0 {
		state.DocumentSummary = summaryBuilder.String()
	} else {
		state.DocumentSummary = response.Choices[0].Content
	}

	state.Messages = []llms.MessageContent{
		llms.TextParts(llms.ChatMessageTypeSystem,
			fmt.Sprintf(`ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŠ©æ•™ï¼Œå¸®åŠ©å­¦ä¹ è€…æ·±å…¥ç†è§£æ–‡æ¡£å†…å®¹ã€‚

æ–‡æ¡£å·²è¢«åˆ‡åˆ†ä¸º %d ä¸ªå—å¹¶å‘é‡åŒ–å­˜å‚¨ã€‚
å½“å›ç­”é—®é¢˜æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µæä¾›ç»™ä½ ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. åŸºäºæ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹å›ç­”å­¦ä¹ è€…çš„é—®é¢˜
2. æä¾›æ·±å…¥çš„è§£é‡Šå’Œç¤ºä¾‹
3. å¼•å¯¼å­¦ä¹ è€…æ€è€ƒå’Œæ¢ç´¢
4. ç”¨æ¸…æ™°ã€å‹å¥½çš„è¯­è¨€äº¤æµ

è¯·åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚`, len(state.DocumentChunks))),
		llms.TextParts(llms.ChatMessageTypeAI, state.DocumentSummary),
	}

	fmt.Println("\n" + strings.Repeat("=", 60))
	fmt.Printf("âœ… åˆ†æå®Œæˆï¼æ–‡æ¡£å·²å‡†å¤‡å°±ç»ªï¼ˆ%d ä¸ªå‘é‡å—ï¼‰\n", len(state.DocumentChunks))
	fmt.Println(strings.Repeat("=", 60))
	fmt.Println("\nğŸ’¡ æç¤ºï¼šè¾“å…¥ 'quit' æˆ– 'exit' å¯ä»¥é€€å‡º")

	state.Stage = "analysis_complete"
	state.ShouldContinue = true
	return state, nil
}

// æ–°å¢å‡½æ•°ï¼šretrieveRelevantChunks - æ£€ç´¢ç›¸å…³æ–‡æ¡£å—
func (t *TutorAgent) retrieveRelevantChunks(ctx context.Context, state TutorState, query string, topK int) ([]DocumentChunk, error) {
	// å°†æŸ¥è¯¢å‘é‡åŒ–
	queryVector, err := state.Embedder.EmbedQuery(ctx, query)
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢å‘é‡åŒ–å¤±è´¥: %v", err)
	}

	// è½¬æ¢ä¸º float32
	queryVector32 := make([]float32, len(queryVector))
	for i, v := range queryVector {
		queryVector32[i] = float32(v)
	}

	// åœ¨ HNSW ç´¢å¼•ä¸­æœç´¢
	results, err := state.VectorIndex.Search(queryVector32, topK, 100)
	if err != nil {
		return nil, fmt.Errorf("å‘é‡æœç´¢å¤±è´¥: %v", err)
	}

	// è·å–å¯¹åº”çš„æ–‡æ¡£å—
	var relevantChunks []DocumentChunk
	for _, result := range results {
		// âœ¨ ä½¿ç”¨æ˜ å°„è¡¨è·å–æ­£ç¡®çš„ç´¢å¼•
		chunkIndex, exists := state.NodeIDToChunkIndex[result.ID]
		if !exists {
			fmt.Printf("âš ï¸  è­¦å‘Šï¼šNodeID %d åœ¨æ˜ å°„è¡¨ä¸­ä¸å­˜åœ¨\n", result.ID)
			continue
		}

		if chunkIndex >= 0 && chunkIndex < len(state.DocumentChunks) {
			chunk := state.DocumentChunks[chunkIndex] // â­ ä½¿ç”¨æ˜ å°„åçš„ç´¢å¼•
			similarity := 1.0 - result.Distance/2.0
			chunk.Metadata["similarity"] = fmt.Sprintf("%.4f", similarity)
			relevantChunks = append(relevantChunks, chunk)
		} else {
			fmt.Printf("âš ï¸  è­¦å‘Šï¼šæ˜ å°„åçš„ç´¢å¼• %d è¶…å‡ºèŒƒå›´ [0, %d)\n", chunkIndex, len(state.DocumentChunks))
		}
	}

	return relevantChunks, nil
}

// æ–°å¢å‡½æ•°ï¼šchatWithRAG - æ”¯æŒ RAG çš„å¯¹è¯äº¤äº’
// ï¼ˆæ›¿ä»£åŸæ¥çš„ chat å‡½æ•°ï¼‰
func (t *TutorAgent) chatWithRAG(ctx context.Context, state TutorState) (TutorState, error) {
	// è·å–ç”¨æˆ·è¾“å…¥
	fmt.Print("\nğŸ’¬ ä½ çš„é—®é¢˜: ")
	if !t.scanner.Scan() {
		state.ShouldContinue = false
		return state, nil
	}

	userInput := strings.TrimSpace(t.scanner.Text())
	state.UserInput = userInput

	// æ£€æŸ¥é€€å‡ºå‘½ä»¤
	if userInput == "quit" || userInput == "exit" {
		state.ShouldContinue = false
		fmt.Println("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿï¼ç¥å­¦ä¹ æ„‰å¿«ï¼")
		return state, nil
	}

	// å¦‚æœç”¨æˆ·ç›´æ¥å›è½¦ï¼ˆç©ºè¾“å…¥ï¼‰ï¼Œæç¤ºé‡æ–°è¾“å…¥
	if userInput == "" {
		fmt.Println("âš ï¸  è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥ 'quit'/'exit' é€€å‡º")
		state.ShouldContinue = true
		return state, nil
	}

	// âœ¨âœ¨âœ¨ æ–°å¢ï¼šRAG æ£€ç´¢ç›¸å…³æ–‡æ¡£å— âœ¨âœ¨âœ¨
	fmt.Print("ğŸ” æ£€ç´¢ç›¸å…³å†…å®¹...")
	relevantChunks, err := t.retrieveRelevantChunks(ctx, state, userInput, 3)
	if err != nil {
		fmt.Printf("\nâš ï¸  æ£€ç´¢å¤±è´¥: %vï¼Œå°†ä½¿ç”¨ä¸€èˆ¬çŸ¥è¯†å›ç­”\n", err)
		relevantChunks = []DocumentChunk{}
	} else {
		fmt.Printf(" æ‰¾åˆ° %d ä¸ªç›¸å…³ç‰‡æ®µ\n", len(relevantChunks))
	}

	// âœ¨âœ¨âœ¨ æ–°å¢ï¼šæ„å»ºå¢å¼ºçš„æç¤ºè¯ âœ¨âœ¨âœ¨
	var contextBuilder strings.Builder
	contextBuilder.WriteString("åŸºäºä»¥ä¸‹ç›¸å…³æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n")

	for i, chunk := range relevantChunks {
		similarity := chunk.Metadata["similarity"]
		contextBuilder.WriteString(fmt.Sprintf("--- ç›¸å…³ç‰‡æ®µ %d (ç›¸ä¼¼åº¦: %s, æ¥æº: %s) ---\n",
			i+1, similarity, chunk.Source))
		contextBuilder.WriteString(chunk.Content)
		contextBuilder.WriteString("\n\n")
	}

	contextBuilder.WriteString(fmt.Sprintf("é—®é¢˜: %s\n\n", userInput))
	contextBuilder.WriteString("è¯·åŸºäºä¸Šè¿°ç›¸å…³å†…å®¹ï¼Œç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚å¦‚æœä¸Šè¿°å†…å®¹ä¸è¶³ä»¥å›ç­”é—®é¢˜ï¼Œè¯·è¯´æ˜å¹¶å°½å¯èƒ½æä¾›å¸®åŠ©ã€‚")

	// âœ¨ ä¿®æ”¹ï¼šæ·»åŠ ç”¨æˆ·æ¶ˆæ¯æ—¶ä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeHuman, contextBuilder.String()))

	fmt.Println() // æ¢è¡Œ

	var responseBuilder strings.Builder
	var isThinking bool
	var hasStartedOutput bool

	response, err := t.model.GenerateContent(ctx, state.Messages,
		llms.WithTemperature(0.7),
		llms.WithMaxTokens(3000),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			text := string(chunk)

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„å¼€å§‹æ ‡è®°
			if strings.Contains(text, "<think>") {
				isThinking = true
				fmt.Print("ğŸ’­ åŠ©æ•™æ€è€ƒ: ")
				hasStartedOutput = true
				return nil
			}

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„ç»“æŸæ ‡è®°
			if strings.Contains(text, "</think>") {
				isThinking = false
				fmt.Println("")
				fmt.Print("ğŸ“ åŠ©æ•™: ")
				return nil
			}

			// è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–æœ€ç»ˆç­”æ¡ˆ
			if isThinking {
				// æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆè¿‡æ»¤æ ‡ç­¾ï¼‰
				cleanText := strings.ReplaceAll(text, "<think>", "")
				fmt.Print(cleanText)
			} else {
				// è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
				if !hasStartedOutput {
					fmt.Print("ğŸ“ åŠ©æ•™: ")
					hasStartedOutput = true
				}
				// è¿‡æ»¤æ ‡ç­¾
				cleanText := strings.ReplaceAll(text, "</think>", "")
				if cleanText != "" {
					fmt.Print(cleanText)
					responseBuilder.WriteString(cleanText)
				}
			}

			return nil
		}),
	)
	if err != nil {
		fmt.Printf("\nâŒ ç”Ÿæˆå›å¤å¤±è´¥: %v\n", err)
		// å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­å¯¹è¯
		state.ShouldContinue = true
		return state, nil
	}

	fmt.Println() // å›å¤ç»“æŸåæ¢è¡Œ

	// âœ¨âœ¨âœ¨ æ–°å¢ï¼šæ˜¾ç¤ºå¼•ç”¨æ¥æº âœ¨âœ¨âœ¨
	if len(relevantChunks) > 0 {
		fmt.Println("\nğŸ“š å¼•ç”¨æ¥æº:")
		for i, chunk := range relevantChunks {
			similarity := chunk.Metadata["similarity"]
			fmt.Printf("  [%d] %s (ç›¸ä¼¼åº¦: %s)\n", i+1, chunk.Source, similarity)
		}
	}

	// è·å– AI å›å¤å†…å®¹
	var aiResponse string
	if responseBuilder.Len() > 0 {
		aiResponse = responseBuilder.String()
	} else {
		aiResponse = response.Choices[0].Content
	}

	// æ·»åŠ  AI å›å¤åˆ°å†å²
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeAI, aiResponse))

	// âœ¨âœ¨âœ¨ æ–°å¢ï¼šé™åˆ¶å†å²æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿ âœ¨âœ¨âœ¨
	if len(state.Messages) > 21 { // 1 system + 1 initial AI + 20 messages (10 è½®å¯¹è¯)
		state.Messages = append(state.Messages[:2], state.Messages[len(state.Messages)-20:]...)
	}

	// ç»§ç»­å¯¹è¯å¾ªç¯
	state.ShouldContinue = true
	state.Stage = "chat_complete"
	return state, nil
}

// chat å¯¹è¯äº¤äº’ - æ”¯æŒå¤šè½®å¯¹è¯
func (t *TutorAgent) chat(ctx context.Context, state TutorState) (TutorState, error) {
	// è·å–ç”¨æˆ·è¾“å…¥
	fmt.Print("\nğŸ’¬ ä½ çš„é—®é¢˜: ")
	if !t.scanner.Scan() {
		state.ShouldContinue = false
		return state, nil
	}

	userInput := strings.TrimSpace(t.scanner.Text())
	state.UserInput = userInput

	// æ£€æŸ¥é€€å‡ºå‘½ä»¤
	if userInput == "quit" || userInput == "exit" {
		state.ShouldContinue = false
		fmt.Println("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½åŠ©æ•™ç³»ç»Ÿï¼ç¥å­¦ä¹ æ„‰å¿«ï¼")
		return state, nil
	}

	// å¦‚æœç”¨æˆ·ç›´æ¥å›è½¦ï¼ˆç©ºè¾“å…¥ï¼‰ï¼Œæç¤ºé‡æ–°è¾“å…¥
	if userInput == "" {
		fmt.Println("âš ï¸  è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œæˆ–è¾“å…¥ 'quit'/'exit' é€€å‡º")
		state.ShouldContinue = true
		return state, nil
	}

	// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeHuman, userInput))

	// ä¿®æ”¹ä¸ºï¼š
	fmt.Println() // æ¢è¡Œ

	var responseBuilder strings.Builder
	var isThinking bool
	var hasStartedOutput bool

	response, err := t.model.GenerateContent(ctx, state.Messages,
		llms.WithTemperature(0.7),
		llms.WithMaxTokens(3000),
		llms.WithStreamingFunc(func(ctx context.Context, chunk []byte) error {
			text := string(chunk)

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„å¼€å§‹æ ‡è®°
			if strings.Contains(text, "<think>") {
				isThinking = true
				fmt.Print("ğŸ’­ åŠ©æ•™æ€è€ƒ: ")
				hasStartedOutput = true
				return nil
			}

			// æ£€æµ‹æ€è€ƒè¿‡ç¨‹çš„ç»“æŸæ ‡è®°
			if strings.Contains(text, "</think>") {
				isThinking = false
				fmt.Println("")
				fmt.Print("ğŸ“ åŠ©æ•™: ")
				return nil
			}

			// è¾“å‡ºæ€è€ƒè¿‡ç¨‹æˆ–æœ€ç»ˆç­”æ¡ˆ
			if isThinking {
				// æ‰“å°æ€è€ƒè¿‡ç¨‹ï¼ˆè¿‡æ»¤æ ‡ç­¾ï¼‰
				cleanText := strings.ReplaceAll(text, "<think>", "")
				fmt.Print(cleanText)
			} else {
				// è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
				if !hasStartedOutput {
					fmt.Print("ğŸ“ åŠ©æ•™: ")
					hasStartedOutput = true
				}
				// è¿‡æ»¤æ ‡ç­¾
				cleanText := strings.ReplaceAll(text, "</think>", "")
				if cleanText != "" {
					fmt.Print(cleanText)
					responseBuilder.WriteString(cleanText)
				}
			}

			return nil
		}),
	)
	if err != nil {
		fmt.Printf("\nâŒ ç”Ÿæˆå›å¤å¤±è´¥: %v\n", err)
		// å³ä½¿å‡ºé”™ä¹Ÿç»§ç»­å¯¹è¯
		state.ShouldContinue = true
		return state, nil
	}

	fmt.Println() // å›å¤ç»“æŸåæ¢è¡Œç¤º

	// è·å– AI å›å¤å†…å®¹
	var aiResponse string
	if responseBuilder.Len() > 0 {
		aiResponse = responseBuilder.String()
	} else {
		aiResponse = response.Choices[0].Content
	}

	// æ·»åŠ  AI å›å¤åˆ°å†å²
	state.Messages = append(state.Messages,
		llms.TextParts(llms.ChatMessageTypeAI, aiResponse))

	// ç»§ç»­å¯¹è¯å¾ªç¯
	state.ShouldContinue = true
	state.Stage = "chat_complete"
	return state, nil
}

// Run è¿è¡ŒåŠ©æ•™ç³»ç»Ÿ
func (t *TutorAgent) Run() error {
	ctx := context.Background()

	// åˆå§‹åŒ–çŠ¶æ€
	initialState := TutorState{
		DocumentContents:   make(map[string]string),
		DocumentChunks:     []DocumentChunk{},
		NodeIDToChunkIndex: make(map[int]int),
		Messages:           []llms.MessageContent{},
		ShouldContinue:     true,
		Stage:              "init",
		VectorIndex:        nil,
		Embedder:           nil,
	}

	_, err := t.graph.Invoke(ctx, initialState)
	if err != nil {
		return fmt.Errorf("æ‰§è¡Œå¤±è´¥: %v", err)
	}

	return nil
}

// æ–°å¢å‡½æ•°ï¼šcosineSimilarity - ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
// ï¼ˆç”¨äºéªŒè¯ï¼Œå¯é€‰ï¼‰
func cosineSimilarity(a, b []float32) float64 {
	if len(a) != len(b) {
		return 0
	}

	var dotProduct, normA, normB float64
	for i := range a {
		dotProduct += float64(a[i]) * float64(b[i])
		normA += float64(a[i]) * float64(a[i])
		normB += float64(b[i]) * float64(b[i])
	}

	if normA == 0 || normB == 0 {
		return 0
	}

	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}
